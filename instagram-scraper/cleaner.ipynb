{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd42acd1",
   "metadata": {},
   "source": [
    "# Instagram Comments Cleaner\n",
    "This notebook cleans the scraped Instagram comments data for semantic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136df932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the scraped Instagram comments\n",
    "dataframe = pd.read_csv('instagram_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe931bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial analysis - see what we're working with\n",
    "print(\"Original dataset info:\")\n",
    "print(f\"Total comments: {len(dataframe)}\")\n",
    "print(f\"Columns: {list(dataframe.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b280827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show detailed statistics before cleaning\n",
    "print(\"Before cleaning:\")\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1989ef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample of text content to understand what needs cleaning\n",
    "print(\"Sample comment texts:\")\n",
    "for i, text in enumerate(dataframe['text'].head(10)):\n",
    "    print(f\"{i+1}. {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cc5bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start cleaning process\n",
    "print(\"🧹 Starting Instagram comment cleaning...\")\n",
    "\n",
    "# 1. Remove comments with empty or null text\n",
    "initial_count = len(dataframe)\n",
    "dataframe = dataframe[dataframe['text'].notna()]\n",
    "dataframe = dataframe[dataframe['text'].str.strip() != '']\n",
    "print(f\"Removed {initial_count - len(dataframe)} empty/null comments\")\n",
    "\n",
    "# 2. Remove comments that are just emojis or single characters\n",
    "emoji_pattern = r'^[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F1E0-\\U0001F1FF\\U00002600-\\U000027BF\\U0001f900-\\U0001f9ff\\U0001f600-\\U0001f64f\\U0001f300-\\U0001f5ff\\U0001f680-\\U0001f6ff\\U0001f1e0-\\U0001f1ff\\s]*$'\n",
    "before_emoji = len(dataframe)\n",
    "dataframe = dataframe[~dataframe['text'].str.match(emoji_pattern, na=False)]\n",
    "print(f\"Removed {before_emoji - len(dataframe)} emoji-only comments\")\n",
    "\n",
    "# 3. Remove very short comments (less than 3 characters)\n",
    "before_short = len(dataframe)\n",
    "dataframe = dataframe[dataframe['text'].str.len() >= 3]\n",
    "print(f\"Removed {before_short - len(dataframe)} very short comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f8ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Remove common spam patterns\n",
    "spam_patterns = [\n",
    "    r'^(dm me|dm|follow me|follow back|f4f|l4l|like4like|follow4follow)$',\n",
    "    r'^(check my.*|visit my.*|link in bio|see my profile).*',\n",
    "    r'^(buy.*|sale.*|discount.*|promo.*|offer.*)$',\n",
    "    r'^(@\\w+\\s*)+$',  # Comments that are just mentions\n",
    "    r'^(first|second|third|1st|2nd|3rd)$',  # Just ordinal numbers\n",
    "    r'^\\.\\.\\.$',  # Just dots\n",
    "]\n",
    "\n",
    "before_spam = len(dataframe)\n",
    "for pattern in spam_patterns:\n",
    "    dataframe = dataframe[~dataframe['text'].str.match(pattern, case=False, na=False)]\n",
    "print(f\"Removed {before_spam - len(dataframe)} spam-like comments\")\n",
    "\n",
    "# 5. Remove comments from potential bot accounts (optional - be careful with this)\n",
    "# Common bot username patterns\n",
    "bot_patterns = r'(bot|spam|fake|auto|promo|sale|buy|shop).*\\d+$'\n",
    "before_bots = len(dataframe)\n",
    "dataframe = dataframe[~dataframe['username'].str.match(bot_patterns, case=False, na=False)]\n",
    "print(f\"Removed {before_bots - len(dataframe)} potential bot comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3af104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Remove duplicate comments (same text from same user)\n",
    "before_duplicates = len(dataframe)\n",
    "dataframe = dataframe.drop_duplicates(subset=['username', 'text'], keep='first')\n",
    "print(f\"Removed {before_duplicates - len(dataframe)} duplicate comments\")\n",
    "\n",
    "# 7. Remove comments that are just URLs or links\n",
    "before_links = len(dataframe)\n",
    "url_pattern = r'^https?://.*$'\n",
    "dataframe = dataframe[~dataframe['text'].str.match(url_pattern, na=False)]\n",
    "print(f\"Removed {before_links - len(dataframe)} URL-only comments\")\n",
    "\n",
    "# 8. Optional: Remove comments with excessive repeated characters (like \"sooooo good\")\n",
    "def has_excessive_repeats(text):\n",
    "    # Check if any character repeats more than 4 times consecutively\n",
    "    return bool(re.search(r'(.)\\1{4,}', str(text)))\n",
    "\n",
    "before_repeats = len(dataframe)\n",
    "dataframe = dataframe[~dataframe['text'].apply(has_excessive_repeats)]\n",
    "print(f\"Removed {before_repeats - len(dataframe)} comments with excessive character repetition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450788e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up text content (normalize without removing)\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Remove leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "dataframe['text'] = dataframe['text'].apply(clean_text)\n",
    "print(\"✅ Normalized text content (removed extra whitespace)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89be72fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final cleanup - remove any rows that became empty after text cleaning\n",
    "before_final = len(dataframe)\n",
    "dataframe = dataframe[dataframe['text'].str.len() > 0]\n",
    "print(f\"Final cleanup: removed {before_final - len(dataframe)} empty entries\")\n",
    "\n",
    "# Reset index\n",
    "dataframe.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b78465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show cleaning results\n",
    "print(\"\\n📊 CLEANING SUMMARY:\")\n",
    "print(f\"✅ Final dataset: {len(dataframe)} comments\")\n",
    "print(f\"📉 Removed: {initial_count - len(dataframe)} comments ({((initial_count - len(dataframe)) / initial_count * 100):.1f}%)\")\n",
    "print(\"\\nAfter cleaning:\")\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5254baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample of cleaned comments\n",
    "print(\"\\n🔍 Sample of cleaned comments:\")\n",
    "for i, row in dataframe.head(10).iterrows():\n",
    "    print(f\"{i+1}. @{row['username']}: {row['text'][:100]}{'...' if len(row['text']) > 100 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca56a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any potential issues in cleaned data\n",
    "print(\"\\n🔍 Quality check:\")\n",
    "print(f\"Comments with very long text (>500 chars): {len(dataframe[dataframe['text'].str.len() > 500])}\")\n",
    "print(f\"Unique usernames: {dataframe['username'].nunique()}\")\n",
    "print(f\"Average comment length: {dataframe['text'].str.len().mean():.1f} characters\")\n",
    "print(f\"Comments with mentions (@): {len(dataframe[dataframe['text'].str.contains('@', na=False)])}\")\n",
    "print(f\"Comments with hashtags (#): {len(dataframe[dataframe['text'].str.contains('#', na=False)])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0824eff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dataset\n",
    "dataframe.to_csv('cleaned_instagram_comments.csv', index=False)\n",
    "print(\"💾 Saved cleaned comments to 'cleaned_instagram_comments.csv')\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
