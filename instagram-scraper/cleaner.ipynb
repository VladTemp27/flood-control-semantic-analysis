{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd42acd1",
   "metadata": {},
   "source": [
    "# Instagram Comments Cleaner\n",
    "This notebook cleans the scraped Instagram comments data for semantic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "136df932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the scraped Instagram comments\n",
    "dataframe = pd.read_csv('instagram_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe931bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset info:\n",
      "Total comments: 288\n",
      "Columns: ['comment_id', 'username', 'text', 'created_at_utc', 'like_count']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at_utc</th>\n",
       "      <th>like_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17942279211025487</td>\n",
       "      <td>nikkijblazaro</td>\n",
       "      <td>üò¢üò¢</td>\n",
       "      <td>2025-09-08 11:54:30+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17916805491172606</td>\n",
       "      <td>mayyyaaa55</td>\n",
       "      <td>kasuhan na bakit kasi pinapatagal pa</td>\n",
       "      <td>2025-09-08 10:59:06+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18073485872032680</td>\n",
       "      <td>_vhsg75</td>\n",
       "      <td>Praying for you sir, na lagi kang healthy para...</td>\n",
       "      <td>2025-09-08 12:12:51+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17858349186498231</td>\n",
       "      <td>elvzav</td>\n",
       "      <td>kaya nga dapat may makasuhan na ano pa bang ka...</td>\n",
       "      <td>2025-09-08 09:34:28+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18036365528480441</td>\n",
       "      <td>ethelguarin</td>\n",
       "      <td>God bless you po Sir. Praying na gabayan ka at...</td>\n",
       "      <td>2025-09-08 16:39:16+00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          comment_id       username  \\\n",
       "0  17942279211025487  nikkijblazaro   \n",
       "1  17916805491172606     mayyyaaa55   \n",
       "2  18073485872032680        _vhsg75   \n",
       "3  17858349186498231         elvzav   \n",
       "4  18036365528480441    ethelguarin   \n",
       "\n",
       "                                                text  \\\n",
       "0                                                 üò¢üò¢   \n",
       "1               kasuhan na bakit kasi pinapatagal pa   \n",
       "2  Praying for you sir, na lagi kang healthy para...   \n",
       "3  kaya nga dapat may makasuhan na ano pa bang ka...   \n",
       "4  God bless you po Sir. Praying na gabayan ka at...   \n",
       "\n",
       "              created_at_utc  like_count  \n",
       "0  2025-09-08 11:54:30+00:00           0  \n",
       "1  2025-09-08 10:59:06+00:00           0  \n",
       "2  2025-09-08 12:12:51+00:00           0  \n",
       "3  2025-09-08 09:34:28+00:00           0  \n",
       "4  2025-09-08 16:39:16+00:00           0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial analysis - see what we're working with\n",
    "print(\"Original dataset info:\")\n",
    "print(f\"Total comments: {len(dataframe)}\")\n",
    "print(f\"Columns: {list(dataframe.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b280827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>like_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.880000e+02</td>\n",
       "      <td>288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.806777e+16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.528785e+14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.784200e+16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.796902e+16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.806619e+16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.809613e+16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.854162e+16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         comment_id  like_count\n",
       "count  2.880000e+02       288.0\n",
       "mean   1.806777e+16         0.0\n",
       "std    1.528785e+14         0.0\n",
       "min    1.784200e+16         0.0\n",
       "25%    1.796902e+16         0.0\n",
       "50%    1.806619e+16         0.0\n",
       "75%    1.809613e+16         0.0\n",
       "max    1.854162e+16         0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show detailed statistics before cleaning\n",
    "print(\"Before cleaning:\")\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1989ef79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample comment texts:\n",
      "1. üò¢üò¢\n",
      "2. kasuhan na bakit kasi pinapatagal pa\n",
      "3. Praying for you sir, na lagi kang healthy para magampanan  mo ng maayos ung trabaho na binigay sayo para mapabuti ang sambayanang Pilipino God bless!\n",
      "4. kaya nga dapat may makasuhan na ano pa bang kailangan , ibalik ang pera\n",
      "5. God bless you po Sir. Praying na gabayan ka at protektahan ka ni Lord para maiayos ang katiwalian at managot ang dapat managot sa DPWH. üôèüôèüôè\n",
      "6. Nakakahiya na talaga\n",
      "7. Kasuhan na agad before they ‚Äúescape‚Äù and hide their loot and bank accounts, issue hold departure order\n",
      "8. Dapat yang mag asawa makulong at ibalik ang pera ng bayan\n",
      "9. Yun ang problema wala nang tiawala ang tao sayo\n",
      "10. Small but terrible üëèüëèüëèüëè\n"
     ]
    }
   ],
   "source": [
    "# Show sample of text content to understand what needs cleaning\n",
    "print(\"Sample comment texts:\")\n",
    "for i, text in enumerate(dataframe['text'].head(10)):\n",
    "    print(f\"{i+1}. {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1cc5bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Starting Instagram comment cleaning...\n",
      "Removed 3 empty/null comments\n",
      "Removed 22 emoji-only comments\n",
      "Removed 17 single-word comments\n",
      "Removed 0 very short comments\n",
      "Removed 0 punctuation-only comments\n"
     ]
    }
   ],
   "source": [
    "# Start cleaning process\n",
    "print(\"üßπ Starting Instagram comment cleaning...\")\n",
    "\n",
    "# 1. Remove comments with empty or null text\n",
    "initial_count = len(dataframe)\n",
    "dataframe = dataframe[dataframe['text'].notna()]\n",
    "dataframe = dataframe[dataframe['text'].str.strip() != '']\n",
    "print(f\"Removed {initial_count - len(dataframe)} empty/null comments\")\n",
    "\n",
    "# 2. Remove comments that are just emojis (more comprehensive emoji patterns)\n",
    "emoji_pattern = r'^[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F1E0-\\U0001F1FF\\U00002600-\\U000027BF\\U0001f900-\\U0001f9ff\\U0001f600-\\U0001f64f\\U0001f300-\\U0001f5ff\\U0001f680-\\U0001f6ff\\U0001f1e0-\\U0001f1ff\\U0001F190-\\U0001F1FF\\U0001F910-\\U0001F96B\\U0001F980-\\U0001F997\\U0001F9C0-\\U0001F9C2\\U0001F9D0-\\U0001F9FF\\U00002702-\\U000027B0\\u2600-\\u26FF\\u2700-\\u27BF\\s]*$'\n",
    "before_emoji = len(dataframe)\n",
    "dataframe = dataframe[~dataframe['text'].str.match(emoji_pattern, na=False)]\n",
    "print(f\"Removed {before_emoji - len(dataframe)} emoji-only comments\")\n",
    "\n",
    "# 3. Remove single-word comments (NEW)\n",
    "def is_single_word(text):\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "    # Split by whitespace and count meaningful words (not just punctuation)\n",
    "    words = [word.strip() for word in str(text).split() if word.strip() and not word.strip() in '.,!?;:']\n",
    "    return len(words) == 1\n",
    "\n",
    "before_single_word = len(dataframe)\n",
    "dataframe = dataframe[~dataframe['text'].apply(is_single_word)]\n",
    "print(f\"Removed {before_single_word - len(dataframe)} single-word comments\")\n",
    "\n",
    "# 4. Remove very short comments (less than 4 characters for better quality)\n",
    "before_short = len(dataframe)\n",
    "dataframe = dataframe[dataframe['text'].str.len() >= 4]\n",
    "print(f\"Removed {before_short - len(dataframe)} very short comments\")\n",
    "\n",
    "# 5. Remove comments that are just punctuation or symbols\n",
    "punctuation_pattern = r'^[^\\w\\s]*$'\n",
    "before_punct = len(dataframe)\n",
    "dataframe = dataframe[~dataframe['text'].str.match(punctuation_pattern, na=False)]\n",
    "print(f\"Removed {before_punct - len(dataframe)} punctuation-only comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a0f8ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 spam/low-quality comments\n",
      "Removed 0 repeated character comments\n",
      "Removed 0 potential bot comments\n",
      "Removed 0 keyboard smash comments\n"
     ]
    }
   ],
   "source": [
    "# 6. Remove common spam and low-quality patterns (ENHANCED)\n",
    "spam_patterns = [\n",
    "    r'^(dm me|dm|follow me|follow back|f4f|l4l|like4like|follow4follow)$',\n",
    "    r'^(check my.*|visit my.*|link in bio|see my profile).*',\n",
    "    r'^(buy.*|sale.*|discount.*|promo.*|offer.*)$',\n",
    "    r'^(@\\w+\\s*)+$',  # Comments that are just mentions\n",
    "    r'^(first|second|third|1st|2nd|3rd|last|early)$',  # Just ordinal numbers\n",
    "    r'^\\.\\.\\.$',  # Just dots\n",
    "    r'^(yes|no|ok|okay|lol|haha|wow|omg|nice|good|bad|cool|awesome|amazing)$',  # Single reaction words\n",
    "    r'^(love|like|want|need|get|see|look|watch|read|buy)$',  # Single action words\n",
    "    r'^[0-9]+$',  # Just numbers\n",
    "    r'^(x|xx|xxx|xxxx)$',  # Just x's\n",
    "    r'^(true|false|real|fake|right|wrong)$',  # Single judgment words\n",
    "]\n",
    "\n",
    "before_spam = len(dataframe)\n",
    "for pattern in spam_patterns:\n",
    "    dataframe = dataframe[~dataframe['text'].str.match(pattern, case=False, na=False)]\n",
    "print(f\"Removed {before_spam - len(dataframe)} spam/low-quality comments\")\n",
    "\n",
    "# 7. Remove comments that are just repeated characters\n",
    "repeated_char_pattern = r'^(.)\\1+$'  # Same character repeated\n",
    "before_repeated = len(dataframe)\n",
    "dataframe = dataframe[~dataframe['text'].str.match(repeated_char_pattern, na=False)]\n",
    "print(f\"Removed {before_repeated - len(dataframe)} repeated character comments\")\n",
    "\n",
    "# 8. Remove comments from potential bot accounts (ENHANCED)\n",
    "bot_patterns = r'(bot|spam|fake|auto|promo|sale|buy|shop|follow|like|comment|sub|subscribe).*\\d{3,}$'\n",
    "before_bots = len(dataframe)\n",
    "dataframe = dataframe[~dataframe['username'].str.match(bot_patterns, case=False, na=False)]\n",
    "print(f\"Removed {before_bots - len(dataframe)} potential bot comments\")\n",
    "\n",
    "# 9. Remove comments that are just keyboard smashing (NEW)\n",
    "def is_keyboard_smash(text):\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "    text = str(text).lower()\n",
    "    # Check for patterns like \"asdfgh\", \"qwerty\", \"hjklm\" etc.\n",
    "    keyboard_patterns = [\n",
    "        'qwerty', 'asdfgh', 'zxcvbn', 'hjklm', 'yuiop',\n",
    "        'qwertyui', 'asdfghjk', 'zxcvbnm',\n",
    "        'abcdefg', '1234567', 'aaaaaaa'\n",
    "    ]\n",
    "    return any(pattern in text for pattern in keyboard_patterns) and len(text) <= 15\n",
    "\n",
    "before_keyboard = len(dataframe)\n",
    "dataframe = dataframe[~dataframe['text'].apply(is_keyboard_smash)]\n",
    "print(f\"Removed {before_keyboard - len(dataframe)} keyboard smash comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3af104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 duplicate comments\n",
      "Removed 0 URL-only comments\n",
      "Removed 20 comments with excessive repetition\n",
      "Removed 0 generic social media expressions\n",
      "Removed 0 overly generic comments\n"
     ]
    }
   ],
   "source": [
    "# 10. Remove duplicate comments (same text from same user)\n",
    "before_duplicates = len(dataframe)\n",
    "dataframe = dataframe.drop_duplicates(subset=['username', 'text'], keep='first')\n",
    "print(f\"Removed {before_duplicates - len(dataframe)} duplicate comments\")\n",
    "\n",
    "# 11. Remove comments that are just URLs or links\n",
    "before_links = len(dataframe)\n",
    "url_pattern = r'^https?://.*$|^www\\..*$|^.*\\.com.*$|^.*\\.org.*$'\n",
    "dataframe = dataframe[~dataframe['text'].str.match(url_pattern, na=False)]\n",
    "print(f\"Removed {before_links - len(dataframe)} URL-only comments\")\n",
    "\n",
    "# 12. Remove comments with excessive repeated characters (enhanced)\n",
    "def has_excessive_repeats(text):\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "    text = str(text)\n",
    "    # Check if any character repeats more than 3 times consecutively (stricter)\n",
    "    if re.search(r'(.)\\1{3,}', text):\n",
    "        return True\n",
    "    # Check for excessive repeated words like \"good good good good\"\n",
    "    words = text.lower().split()\n",
    "    if len(words) > 1:\n",
    "        for i in range(len(words) - 2):\n",
    "            if words[i] == words[i+1] == words[i+2]:  # Same word 3+ times\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "before_repeats = len(dataframe)\n",
    "dataframe = dataframe[~dataframe['text'].apply(has_excessive_repeats)]\n",
    "print(f\"Removed {before_repeats - len(dataframe)} comments with excessive repetition\")\n",
    "\n",
    "# 13. Remove comments that are just common social media expressions (NEW)\n",
    "social_expressions = [\n",
    "    r'^(tag|tagged|tagging).*$',\n",
    "    r'^(share|shared|sharing).*$',\n",
    "    r'^(story|stories).*$',\n",
    "    r'^(post|posted|posting).*$',\n",
    "    r'^(caption|captions).*$',\n",
    "    r'^(photo|pic|picture|image).*$',\n",
    "    r'^(video|vid|vlog).*$',\n",
    "]\n",
    "\n",
    "before_social = len(dataframe)\n",
    "for pattern in social_expressions:\n",
    "    dataframe = dataframe[~dataframe['text'].str.match(pattern, case=False, na=False)]\n",
    "print(f\"Removed {before_social - len(dataframe)} generic social media expressions\")\n",
    "\n",
    "# 14. Remove comments that are too generic/meaningless (NEW)\n",
    "generic_comments = [\n",
    "    r'^(this|that|it|what|when|where|how|why|who)$',\n",
    "    r'^(same|different|similar|other|another)$',\n",
    "    r'^(me|you|him|her|them|us|we|they)$',\n",
    "    r'^(my|your|his|her|their|our)$',\n",
    "    r'^(here|there|now|then|today|yesterday|tomorrow)$',\n",
    "]\n",
    "\n",
    "before_generic = len(dataframe)\n",
    "for pattern in generic_comments:\n",
    "    dataframe = dataframe[~dataframe['text'].str.match(pattern, case=False, na=False)]\n",
    "print(f\"Removed {before_generic - len(dataframe)} overly generic comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "450788e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Normalized text content (cleaned punctuation and slang)\n"
     ]
    }
   ],
   "source": [
    "# Clean up text content (enhanced normalization)\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    # Remove excessive punctuation (more than 2 consecutive)\n",
    "    text = re.sub(r'[.]{3,}', '...', text)  # Multiple dots to ellipsis\n",
    "    text = re.sub(r'[!]{2,}', '!', text)    # Multiple exclamations to one\n",
    "    text = re.sub(r'[?]{2,}', '?', text)    # Multiple questions to one\n",
    "    \n",
    "    # Remove excessive whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Remove leading/trailing whitespace and punctuation\n",
    "    text = text.strip(' .,!?;:')\n",
    "    \n",
    "    # Normalize common internet slang to more readable forms\n",
    "    text = re.sub(r'\\bu\\b', 'you', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\bur\\b', 'your', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\br\\b', 'are', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    return text\n",
    "\n",
    "dataframe['text'] = dataframe['text'].apply(clean_text)\n",
    "print(\"‚úÖ Normalized text content (cleaned punctuation and slang)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb159cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 92 comments lacking meaningful content\n",
      "Removed 0 context-less questions\n"
     ]
    }
   ],
   "source": [
    "# 15. Advanced content quality filtering (NEW)\n",
    "def is_meaningful_comment(text):\n",
    "    \"\"\"Check if comment has meaningful content for semantic analysis\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "    \n",
    "    text = str(text).strip().lower()\n",
    "    \n",
    "    # Must have at least 2 words\n",
    "    words = [w for w in text.split() if w.isalpha()]\n",
    "    if len(words) < 2:\n",
    "        return False\n",
    "    \n",
    "    # Check for actual sentence structure (has both nouns/verbs and connects words)\n",
    "    connecting_words = ['and', 'or', 'but', 'so', 'because', 'when', 'where', 'how', 'why', 'what', 'that', 'this', 'is', 'are', 'was', 'were', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'should', 'could', 'can', 'may', 'might']\n",
    "    has_structure = any(word in text for word in connecting_words)\n",
    "    \n",
    "    # Check if it's not just a list of adjectives\n",
    "    adjectives_only = ['good', 'bad', 'nice', 'cool', 'awesome', 'amazing', 'great', 'terrible', 'horrible', 'beautiful', 'ugly', 'hot', 'cold', 'big', 'small']\n",
    "    is_just_adjectives = all(word in adjectives_only for word in words)\n",
    "    \n",
    "    return has_structure and not is_just_adjectives\n",
    "\n",
    "before_meaningful = len(dataframe)\n",
    "dataframe = dataframe[dataframe['text'].apply(is_meaningful_comment)]\n",
    "print(f\"Removed {before_meaningful - len(dataframe)} comments lacking meaningful content\")\n",
    "\n",
    "# 16. Remove comments that are just questions without context (NEW)\n",
    "context_less_questions = [\n",
    "    r'^\\?+$',  # Just question marks\n",
    "    r'^(what|why|how|when|where|who)\\?*$',  # Single question words\n",
    "    r'^(really|seriously|actually)\\?*$',  # Single incredulous words\n",
    "    r'^(huh|eh|hmm|uhh|umm)\\?*$',  # Thinking sounds\n",
    "]\n",
    "\n",
    "before_questions = len(dataframe)\n",
    "for pattern in context_less_questions:\n",
    "    dataframe = dataframe[~dataframe['text'].str.match(pattern, case=False, na=False)]\n",
    "print(f\"Removed {before_questions - len(dataframe)} context-less questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89be72fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final cleanup: removed 0 empty entries\n"
     ]
    }
   ],
   "source": [
    "# Final cleanup - remove any rows that became empty after text cleaning\n",
    "before_final = len(dataframe)\n",
    "dataframe = dataframe[dataframe['text'].str.len() > 0]\n",
    "print(f\"Final cleanup: removed {before_final - len(dataframe)} empty entries\")\n",
    "\n",
    "# Reset index\n",
    "dataframe.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b78465c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä CLEANING SUMMARY:\n",
      "‚úÖ Final dataset: 134 comments\n",
      "üìâ Removed: 154 comments (53.5%)\n",
      "\n",
      "After cleaning:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>like_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.340000e+02</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.808316e+16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.537480e+14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.784200e+16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.798849e+16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.807404e+16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.810838e+16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.854162e+16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         comment_id  like_count\n",
       "count  1.340000e+02       134.0\n",
       "mean   1.808316e+16         0.0\n",
       "std    1.537480e+14         0.0\n",
       "min    1.784200e+16         0.0\n",
       "25%    1.798849e+16         0.0\n",
       "50%    1.807404e+16         0.0\n",
       "75%    1.810838e+16         0.0\n",
       "max    1.854162e+16         0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show cleaning results\n",
    "print(\"\\nüìä CLEANING SUMMARY:\")\n",
    "print(f\"‚úÖ Final dataset: {len(dataframe)} comments\")\n",
    "print(f\"üìâ Removed: {initial_count - len(dataframe)} comments ({((initial_count - len(dataframe)) / initial_count * 100):.1f}%)\")\n",
    "print(\"\\nAfter cleaning:\")\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5254baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Sample of cleaned comments:\n",
      "1. @_vhsg75: Praying for you sir, na lagi kang healthy para magampanan mo ng maayos ung trabaho na binigay sayo p...\n",
      "2. @elvzav: kaya nga dapat may makasuhan na ano pa bang kailangan , ibalik ang pera\n",
      "3. @ethelguarin: God bless you po Sir. Praying na gabayan ka at protektahan ka ni Lord para maiayos ang katiwalian at...\n",
      "4. @iamgatch69: Kasuhan na agad before they ‚Äúescape‚Äù and hide their loot and bank accounts, issue hold departure ord...\n",
      "5. @cewster_: Tapos bigla akong na gising.. Panaginip lang pala üòÇ\n",
      "6. @lorabatesebastian: Words are easy. Kelan ang aksyon\n",
      "7. @kura6eru: The untouchable will be touchedü§£\n",
      "8. @jerwin6330: nice para naman ibang issue nanaman ibato ng mga DDS sa pangulo hanap ulit sila ng paninira sa gobye...\n",
      "9. @mackay_75: I hope so , because we are watching the hearing and it seems like ‚Ä¶ not right\n",
      "10. @johnglenn274: TUMBUKIN NA AGAD ANG PINAKA PUNO. Hindi naman KIKILOS yang mga career officials na yan kung ealang b...\n"
     ]
    }
   ],
   "source": [
    "# Show sample of cleaned comments\n",
    "print(\"\\nüîç Sample of cleaned comments:\")\n",
    "for i, row in dataframe.head(10).iterrows():\n",
    "    print(f\"{i+1}. @{row['username']}: {row['text'][:100]}{'...' if len(row['text']) > 100 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ca56a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Quality check:\n",
      "Comments with very long text (>500 chars): 2\n",
      "Unique usernames: 133\n",
      "Average comment length: 110.7 characters\n",
      "Comments with mentions (@): 1\n",
      "Comments with hashtags (#): 1\n"
     ]
    }
   ],
   "source": [
    "# Check for any potential issues in cleaned data\n",
    "print(\"\\nüîç Quality check:\")\n",
    "print(f\"Comments with very long text (>500 chars): {len(dataframe[dataframe['text'].str.len() > 500])}\")\n",
    "print(f\"Unique usernames: {dataframe['username'].nunique()}\")\n",
    "print(f\"Average comment length: {dataframe['text'].str.len().mean():.1f} characters\")\n",
    "print(f\"Comments with mentions (@): {len(dataframe[dataframe['text'].str.contains('@', na=False)])}\")\n",
    "print(f\"Comments with hashtags (#): {len(dataframe[dataframe['text'].str.contains('#', na=False)])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0824eff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved cleaned comments to 'cleaned_instagram_comments.csv')\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned dataset\n",
    "dataframe.to_csv('cleaned_instagram_comments.csv', index=False)\n",
    "print(\"üíæ Saved cleaned comments to 'cleaned_instagram_comments.csv')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
